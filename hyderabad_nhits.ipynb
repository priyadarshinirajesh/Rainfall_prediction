{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76a3184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Running CNN-LSTM =====\n",
      "Epoch 1/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7280 - auc_3: 0.8020 - loss: 0.6581 - precision_3: 0.8271 - recall_3: 0.6962 - val_accuracy: 0.7645 - val_auc_3: 0.7323 - val_loss: 0.6642 - val_precision_3: 0.2903 - val_recall_3: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8092 - auc_3: 0.8555 - loss: 0.5670 - precision_3: 0.8186 - recall_3: 0.8797 - val_accuracy: 0.8410 - val_auc_3: 0.7275 - val_loss: 0.5708 - val_precision_3: 0.3871 - val_recall_3: 0.6316 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8184 - auc_3: 0.8594 - loss: 0.4579 - precision_3: 0.8409 - recall_3: 0.8633 - val_accuracy: 0.9235 - val_auc_3: 0.7654 - val_loss: 0.3913 - val_precision_3: 0.6757 - val_recall_3: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8046 - auc_3: 0.8774 - loss: 0.4306 - precision_3: 0.8461 - recall_3: 0.8278 - val_accuracy: 0.9205 - val_auc_3: 0.7568 - val_loss: 0.4407 - val_precision_3: 0.6429 - val_recall_3: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8192 - auc_3: 0.8804 - loss: 0.4246 - precision_3: 0.8462 - recall_3: 0.8570 - val_accuracy: 0.9235 - val_auc_3: 0.7598 - val_loss: 0.3909 - val_precision_3: 0.6757 - val_recall_3: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8123 - auc_3: 0.8814 - loss: 0.4224 - precision_3: 0.8471 - recall_3: 0.8418 - val_accuracy: 0.9235 - val_auc_3: 0.7511 - val_loss: 0.4098 - val_precision_3: 0.6757 - val_recall_3: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8115 - auc_3: 0.8821 - loss: 0.4202 - precision_3: 0.8469 - recall_3: 0.8405 - val_accuracy: 0.9205 - val_auc_3: 0.7573 - val_loss: 0.3773 - val_precision_3: 0.6667 - val_recall_3: 0.6316 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8138 - auc_3: 0.8792 - loss: 0.4237 - precision_3: 0.8493 - recall_3: 0.8418 - val_accuracy: 0.9205 - val_auc_3: 0.7482 - val_loss: 0.4178 - val_precision_3: 0.6579 - val_recall_3: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8161 - auc_3: 0.8867 - loss: 0.4145 - precision_3: 0.8526 - recall_3: 0.8418 - val_accuracy: 0.8838 - val_auc_3: 0.7549 - val_loss: 0.4700 - val_precision_3: 0.5000 - val_recall_3: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8176 - auc_3: 0.8893 - loss: 0.4089 - precision_3: 0.8511 - recall_3: 0.8468 - val_accuracy: 0.9266 - val_auc_3: 0.7674 - val_loss: 0.3358 - val_precision_3: 0.7188 - val_recall_3: 0.6053 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8176 - auc_3: 0.8869 - loss: 0.4127 - precision_3: 0.8538 - recall_3: 0.8430 - val_accuracy: 0.9235 - val_auc_3: 0.7568 - val_loss: 0.4012 - val_precision_3: 0.6757 - val_recall_3: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8199 - auc_3: 0.8859 - loss: 0.4114 - precision_3: 0.8499 - recall_3: 0.8532 - val_accuracy: 0.9235 - val_auc_3: 0.7643 - val_loss: 0.3799 - val_precision_3: 0.6757 - val_recall_3: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8169 - auc_3: 0.8892 - loss: 0.4070 - precision_3: 0.8465 - recall_3: 0.8519 - val_accuracy: 0.9235 - val_auc_3: 0.7606 - val_loss: 0.3852 - val_precision_3: 0.6757 - val_recall_3: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8230 - auc_3: 0.8897 - loss: 0.4064 - precision_3: 0.8498 - recall_3: 0.8595 - val_accuracy: 0.9205 - val_auc_3: 0.7596 - val_loss: 0.3805 - val_precision_3: 0.6667 - val_recall_3: 0.6316 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8245 - auc_3: 0.8910 - loss: 0.4041 - precision_3: 0.8519 - recall_3: 0.8595 - val_accuracy: 0.9205 - val_auc_3: 0.7587 - val_loss: 0.3973 - val_precision_3: 0.6579 - val_recall_3: 0.6579 - learning_rate: 5.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8161 - auc_3: 0.8915 - loss: 0.4044 - precision_3: 0.8535 - recall_3: 0.8405 - val_accuracy: 0.9083 - val_auc_3: 0.7613 - val_loss: 0.4216 - val_precision_3: 0.5870 - val_recall_3: 0.7105 - learning_rate: 5.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8230 - auc_3: 0.8936 - loss: 0.4004 - precision_3: 0.8489 - recall_3: 0.8608 - val_accuracy: 0.9235 - val_auc_3: 0.7629 - val_loss: 0.3996 - val_precision_3: 0.6667 - val_recall_3: 0.6842 - learning_rate: 5.0000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8161 - auc_3: 0.8935 - loss: 0.4001 - precision_3: 0.8481 - recall_3: 0.8481 - val_accuracy: 0.9205 - val_auc_3: 0.7637 - val_loss: 0.3933 - val_precision_3: 0.6579 - val_recall_3: 0.6579 - learning_rate: 5.0000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8245 - auc_3: 0.8942 - loss: 0.3982 - precision_3: 0.8519 - recall_3: 0.8595 - val_accuracy: 0.9205 - val_auc_3: 0.7642 - val_loss: 0.4055 - val_precision_3: 0.6500 - val_recall_3: 0.6842 - learning_rate: 2.5000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8222 - auc_3: 0.8931 - loss: 0.4008 - precision_3: 0.8514 - recall_3: 0.8557 - val_accuracy: 0.8930 - val_auc_3: 0.7626 - val_loss: 0.4277 - val_precision_3: 0.5294 - val_recall_3: 0.7105 - learning_rate: 2.5000e-05\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Accuracy: 0.8273809523809523\n",
      "Precision: 0.8769230769230769\n",
      "Recall: 0.8341463414634146\n",
      "F1: 0.855\n",
      "ROC-AUC: 0.88951778067399\n",
      "[[107  24]\n",
      " [ 34 171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       131\n",
      "           1       0.88      0.83      0.85       205\n",
      "\n",
      "    accuracy                           0.83       336\n",
      "   macro avg       0.82      0.83      0.82       336\n",
      "weighted avg       0.83      0.83      0.83       336\n",
      "\n",
      "\n",
      "===== Running Transformer =====\n",
      "Epoch 1/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6989 - auc_4: 0.7484 - loss: 0.5934 - precision_4: 0.6983 - recall_4: 0.8848 - val_accuracy: 0.8012 - val_auc_4: 0.7638 - val_loss: 0.6090 - val_precision_4: 0.3333 - val_recall_4: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8153 - auc_4: 0.8559 - loss: 0.4672 - precision_4: 0.8249 - recall_4: 0.8823 - val_accuracy: 0.9205 - val_auc_4: 0.8014 - val_loss: 0.3749 - val_precision_4: 0.6667 - val_recall_4: 0.6316 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8115 - auc_4: 0.8749 - loss: 0.4315 - precision_4: 0.8426 - recall_4: 0.8468 - val_accuracy: 0.9235 - val_auc_4: 0.8137 - val_loss: 0.3650 - val_precision_4: 0.6667 - val_recall_4: 0.6842 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8115 - auc_4: 0.8767 - loss: 0.4289 - precision_4: 0.8443 - recall_4: 0.8443 - val_accuracy: 0.9205 - val_auc_4: 0.7960 - val_loss: 0.3424 - val_precision_4: 0.6765 - val_recall_4: 0.6053 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8146 - auc_4: 0.8744 - loss: 0.4327 - precision_4: 0.8451 - recall_4: 0.8494 - val_accuracy: 0.9113 - val_auc_4: 0.7938 - val_loss: 0.4767 - val_precision_4: 0.6000 - val_recall_4: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8169 - auc_4: 0.8776 - loss: 0.4260 - precision_4: 0.8405 - recall_4: 0.8608 - val_accuracy: 0.9205 - val_auc_4: 0.7927 - val_loss: 0.3406 - val_precision_4: 0.6667 - val_recall_4: 0.6316 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8061 - auc_4: 0.8808 - loss: 0.4243 - precision_4: 0.8456 - recall_4: 0.8316 - val_accuracy: 0.9113 - val_auc_4: 0.7961 - val_loss: 0.4667 - val_precision_4: 0.6000 - val_recall_4: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8130 - auc_4: 0.8811 - loss: 0.4224 - precision_4: 0.8509 - recall_4: 0.8380 - val_accuracy: 0.8226 - val_auc_4: 0.7890 - val_loss: 0.5344 - val_precision_4: 0.3649 - val_recall_4: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8253 - auc_4: 0.8804 - loss: 0.4208 - precision_4: 0.8530 - recall_4: 0.8595 - val_accuracy: 0.9205 - val_auc_4: 0.7873 - val_loss: 0.3224 - val_precision_4: 0.6765 - val_recall_4: 0.6053 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8161 - auc_4: 0.8801 - loss: 0.4225 - precision_4: 0.8472 - recall_4: 0.8494 - val_accuracy: 0.9235 - val_auc_4: 0.7786 - val_loss: 0.3723 - val_precision_4: 0.6757 - val_recall_4: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8123 - auc_4: 0.8837 - loss: 0.4160 - precision_4: 0.8445 - recall_4: 0.8456 - val_accuracy: 0.9266 - val_auc_4: 0.7791 - val_loss: 0.3769 - val_precision_4: 0.6750 - val_recall_4: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8115 - auc_4: 0.8816 - loss: 0.4195 - precision_4: 0.8523 - recall_4: 0.8329 - val_accuracy: 0.9235 - val_auc_4: 0.7812 - val_loss: 0.3851 - val_precision_4: 0.6667 - val_recall_4: 0.6842 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8176 - auc_4: 0.8875 - loss: 0.4123 - precision_4: 0.8459 - recall_4: 0.8544 - val_accuracy: 0.9205 - val_auc_4: 0.7803 - val_loss: 0.3632 - val_precision_4: 0.6579 - val_recall_4: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8146 - auc_4: 0.8838 - loss: 0.4152 - precision_4: 0.8460 - recall_4: 0.8481 - val_accuracy: 0.9174 - val_auc_4: 0.7778 - val_loss: 0.3335 - val_precision_4: 0.6571 - val_recall_4: 0.6053 - learning_rate: 5.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8146 - auc_4: 0.8821 - loss: 0.4183 - precision_4: 0.8486 - recall_4: 0.8443 - val_accuracy: 0.9205 - val_auc_4: 0.7746 - val_loss: 0.3794 - val_precision_4: 0.6579 - val_recall_4: 0.6579 - learning_rate: 5.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8238 - auc_4: 0.8866 - loss: 0.4107 - precision_4: 0.8518 - recall_4: 0.8582 - val_accuracy: 0.9266 - val_auc_4: 0.7832 - val_loss: 0.3906 - val_precision_4: 0.6750 - val_recall_4: 0.7105 - learning_rate: 5.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8176 - auc_4: 0.8836 - loss: 0.4173 - precision_4: 0.8503 - recall_4: 0.8481 - val_accuracy: 0.9235 - val_auc_4: 0.7816 - val_loss: 0.4023 - val_precision_4: 0.6585 - val_recall_4: 0.7105 - learning_rate: 5.0000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8176 - auc_4: 0.8860 - loss: 0.4115 - precision_4: 0.8433 - recall_4: 0.8582 - val_accuracy: 0.9205 - val_auc_4: 0.7760 - val_loss: 0.3720 - val_precision_4: 0.6579 - val_recall_4: 0.6579 - learning_rate: 2.5000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8184 - auc_4: 0.8882 - loss: 0.4092 - precision_4: 0.8504 - recall_4: 0.8494 - val_accuracy: 0.9235 - val_auc_4: 0.7807 - val_loss: 0.3693 - val_precision_4: 0.6667 - val_recall_4: 0.6842 - learning_rate: 2.5000e-05\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Accuracy: 0.8244047619047619\n",
      "Precision: 0.8762886597938144\n",
      "Recall: 0.8292682926829268\n",
      "F1: 0.8521303258145363\n",
      "ROC-AUC: 0.8904487060137777\n",
      "[[107  24]\n",
      " [ 35 170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78       131\n",
      "           1       0.88      0.83      0.85       205\n",
      "\n",
      "    accuracy                           0.82       336\n",
      "   macro avg       0.81      0.82      0.82       336\n",
      "weighted avg       0.83      0.82      0.83       336\n",
      "\n",
      "\n",
      "===== Running TCN =====\n",
      "Epoch 1/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6398 - auc_5: 0.6997 - loss: 0.6313 - precision_5: 0.6423 - recall_5: 0.9139 - val_accuracy: 0.3456 - val_auc_5: 0.7481 - val_loss: 0.7219 - val_precision_5: 0.1239 - val_recall_5: 0.7632 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7862 - auc_5: 0.8581 - loss: 0.5124 - precision_5: 0.7733 - recall_5: 0.9152 - val_accuracy: 0.8532 - val_auc_5: 0.7733 - val_loss: 0.5626 - val_precision_5: 0.4219 - val_recall_5: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8123 - auc_5: 0.8639 - loss: 0.4527 - precision_5: 0.8295 - recall_5: 0.8684 - val_accuracy: 0.9205 - val_auc_5: 0.7886 - val_loss: 0.4312 - val_precision_5: 0.6429 - val_recall_5: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8176 - auc_5: 0.8694 - loss: 0.4365 - precision_5: 0.8424 - recall_5: 0.8595 - val_accuracy: 0.9205 - val_auc_5: 0.7770 - val_loss: 0.4158 - val_precision_5: 0.6429 - val_recall_5: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8169 - auc_5: 0.8723 - loss: 0.4340 - precision_5: 0.8457 - recall_5: 0.8532 - val_accuracy: 0.9235 - val_auc_5: 0.7788 - val_loss: 0.4037 - val_precision_5: 0.6585 - val_recall_5: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8115 - auc_5: 0.8748 - loss: 0.4332 - precision_5: 0.8400 - recall_5: 0.8506 - val_accuracy: 0.9205 - val_auc_5: 0.7948 - val_loss: 0.3537 - val_precision_5: 0.6579 - val_recall_5: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8184 - auc_5: 0.8818 - loss: 0.4240 - precision_5: 0.8478 - recall_5: 0.8532 - val_accuracy: 0.9235 - val_auc_5: 0.7952 - val_loss: 0.3679 - val_precision_5: 0.6667 - val_recall_5: 0.6842 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8077 - auc_5: 0.8818 - loss: 0.4217 - precision_5: 0.8424 - recall_5: 0.8392 - val_accuracy: 0.9266 - val_auc_5: 0.7832 - val_loss: 0.3826 - val_precision_5: 0.6750 - val_recall_5: 0.7105 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8107 - auc_5: 0.8834 - loss: 0.4189 - precision_5: 0.8441 - recall_5: 0.8430 - val_accuracy: 0.9205 - val_auc_5: 0.7790 - val_loss: 0.3663 - val_precision_5: 0.6579 - val_recall_5: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8130 - auc_5: 0.8869 - loss: 0.4136 - precision_5: 0.8421 - recall_5: 0.8506 - val_accuracy: 0.9235 - val_auc_5: 0.7780 - val_loss: 0.3773 - val_precision_5: 0.6667 - val_recall_5: 0.6842 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8153 - auc_5: 0.8825 - loss: 0.4196 - precision_5: 0.8462 - recall_5: 0.8494 - val_accuracy: 0.9266 - val_auc_5: 0.7759 - val_loss: 0.3902 - val_precision_5: 0.6750 - val_recall_5: 0.7105 - learning_rate: 5.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8169 - auc_5: 0.8890 - loss: 0.4088 - precision_5: 0.8431 - recall_5: 0.8570 - val_accuracy: 0.9266 - val_auc_5: 0.7755 - val_loss: 0.3931 - val_precision_5: 0.6750 - val_recall_5: 0.7105 - learning_rate: 5.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8222 - auc_5: 0.8877 - loss: 0.4097 - precision_5: 0.8479 - recall_5: 0.8608 - val_accuracy: 0.9205 - val_auc_5: 0.7746 - val_loss: 0.3763 - val_precision_5: 0.6579 - val_recall_5: 0.6579 - learning_rate: 5.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8161 - auc_5: 0.8809 - loss: 0.4204 - precision_5: 0.8490 - recall_5: 0.8468 - val_accuracy: 0.9235 - val_auc_5: 0.7788 - val_loss: 0.3768 - val_precision_5: 0.6667 - val_recall_5: 0.6842 - learning_rate: 5.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8130 - auc_5: 0.8851 - loss: 0.4147 - precision_5: 0.8509 - recall_5: 0.8380 - val_accuracy: 0.9235 - val_auc_5: 0.7766 - val_loss: 0.4073 - val_precision_5: 0.6585 - val_recall_5: 0.7105 - learning_rate: 2.5000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8215 - auc_5: 0.8882 - loss: 0.4100 - precision_5: 0.8451 - recall_5: 0.8633 - val_accuracy: 0.9235 - val_auc_5: 0.7772 - val_loss: 0.3996 - val_precision_5: 0.6585 - val_recall_5: 0.7105 - learning_rate: 2.5000e-05\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Accuracy: 0.8184523809523809\n",
      "Precision: 0.8495145631067961\n",
      "Recall: 0.8536585365853658\n",
      "F1: 0.851581508515815\n",
      "ROC-AUC: 0.8870601377769504\n",
      "[[100  31]\n",
      " [ 30 175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       131\n",
      "           1       0.85      0.85      0.85       205\n",
      "\n",
      "    accuracy                           0.82       336\n",
      "   macro avg       0.81      0.81      0.81       336\n",
      "weighted avg       0.82      0.82      0.82       336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rainfall_models_adilabad.py\n",
    "# Comparative Study: CNN-LSTM vs Transformer vs TCN\n",
    "# Sequence length = 30 | Train years = 2019–2023 | Test year = 2024\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "DATA_FILES = {\n",
    "    2019: r\"C:\\Users\\priya\\rainfall_prediction\\Rainfall_prediction\\datasets\\hyderabad_2019.csv\",\n",
    "    2020: r\"C:\\Users\\priya\\rainfall_prediction\\Rainfall_prediction\\datasets\\hyderabad_2020.csv\",\n",
    "    2021: r\"C:\\Users\\priya\\rainfall_prediction\\Rainfall_prediction\\datasets\\hyderabad_2021.csv\",\n",
    "    2022: r\"C:\\Users\\priya\\rainfall_prediction\\Rainfall_prediction\\datasets\\hyderabad_2022.csv\",\n",
    "    2023: r\"C:\\Users\\priya\\rainfall_prediction\\Rainfall_prediction\\datasets\\hyderabad_2023.csv\",\n",
    "    2024: r\"C:\\Users\\priya\\rainfall_prediction\\Rainfall_prediction\\datasets\\hyderabad_2024.csv\",\n",
    "}\n",
    "\n",
    "TRAIN_YEARS = [2019, 2020, 2021, 2022, 2023]\n",
    "TEST_YEAR = 2024\n",
    "SEQ_LENGTH = 30\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD + FEATURE ENGINEERING\n",
    "# -------------------------------\n",
    "def load_and_prepare_data(file_map=DATA_FILES):\n",
    "    dfs = []\n",
    "    for year in sorted(file_map.keys()):\n",
    "        df = pd.read_csv(file_map[year]).assign(YEAR=year)\n",
    "        dfs.append(df)\n",
    "\n",
    "    full_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    required = ['YEAR', 'MO', 'DY', 'PRECTOTCORR']\n",
    "    for col in required:\n",
    "        full_df[col] = pd.to_numeric(full_df[col], errors='coerce')\n",
    "    full_df.dropna(subset=required, inplace=True)\n",
    "\n",
    "    full_df[\"datetime\"] = pd.to_datetime(dict(\n",
    "        year=full_df['YEAR'], month=full_df['MO'], day=full_df['DY']\n",
    "    ))\n",
    "    full_df[\"DOY\"] = full_df[\"datetime\"].dt.dayofyear\n",
    "    full_df[\"sin_DOY\"] = np.sin(2*np.pi*full_df[\"DOY\"]/365.25)\n",
    "    full_df[\"cos_DOY\"] = np.cos(2*np.pi*full_df[\"DOY\"]/365.25)\n",
    "\n",
    "    # Lag features\n",
    "    for lag in [1,3,7,14,30]:\n",
    "        full_df[f\"PRECTOTCORR_lag{lag}\"] = full_df[\"PRECTOTCORR\"].shift(lag)\n",
    "\n",
    "    # Sea Level Temp (Hyderabad elev = 542m)\n",
    "    full_df[\"SLT\"] = full_df[\"TS\"] + (0.0065 * 542)\n",
    "\n",
    "    full_df.dropna(inplace=True)\n",
    "\n",
    "    features = [\n",
    "        \"SLT\",\"SLP\",\"T2M\",\"TS\",\"T2M_MAX\",\"T2M_MIN\",\n",
    "        \"RH2M\",\"WS10M_MAX\",\"WS10M_MIN\",\n",
    "        \"sin_DOY\",\"cos_DOY\",\n",
    "        \"PRECTOTCORR_lag1\",\"PRECTOTCORR_lag3\",\"PRECTOTCORR_lag7\",\n",
    "        \"PRECTOTCORR_lag14\",\"PRECTOTCORR_lag30\"\n",
    "    ]\n",
    "\n",
    "    full_df[\"Rain\"] = (full_df[\"PRECTOTCORR\"] > 0).astype(int)\n",
    "\n",
    "    train_df = full_df[full_df[\"YEAR\"].isin(TRAIN_YEARS)]\n",
    "    test_df  = full_df[full_df[\"YEAR\"] == TEST_YEAR]\n",
    "\n",
    "    return train_df, test_df, features, \"Rain\"\n",
    "\n",
    "# -------------------------------\n",
    "# PREPROCESS: SCALE + SMOTE + SEQUENCES\n",
    "# -------------------------------\n",
    "def preprocess_and_balance(train_df, test_df, features, target):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(train_df[features])\n",
    "    X_test_scaled  = scaler.transform(test_df[features])\n",
    "\n",
    "    sm = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_res, y_res = sm.fit_resample(X_train_scaled, train_df[target])\n",
    "\n",
    "    train_bal = pd.DataFrame(X_res, columns=features)\n",
    "    train_bal[target] = y_res\n",
    "\n",
    "    test_proc = pd.DataFrame(X_test_scaled, columns=features, index=test_df.index)\n",
    "    test_proc[target] = test_df[target]\n",
    "    test_proc[\"DOY\"] = test_df[\"DOY\"]\n",
    "\n",
    "    return train_bal, test_proc, scaler\n",
    "\n",
    "def create_sequences(df, features, target, seq_len):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - seq_len):\n",
    "        X.append(df[features].iloc[i:i+seq_len].values)\n",
    "        y.append(df[target].iloc[i+seq_len])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -------------------------------\n",
    "# MODEL A — CNN-LSTM\n",
    "# -------------------------------\n",
    "def build_cnn_lstm(seq_len, feat):\n",
    "    inp = Input(shape=(seq_len, feat))\n",
    "    x = Conv1D(64, 3, padding=\"same\", activation=\"relu\")(inp)\n",
    "    x = Conv1D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = LSTM(64)(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", tf.keras.metrics.Precision(),\n",
    "                 tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# MODEL B — Transformer\n",
    "# -------------------------------\n",
    "def build_transformer(seq_len, feat, d_model=128, heads=4, ff_dim=256):\n",
    "    inp = Input(shape=(seq_len, feat))\n",
    "    x = Dense(d_model)(inp)\n",
    "\n",
    "    pos = tf.Variable(tf.random.normal([1, seq_len, d_model]), trainable=True)\n",
    "    x = x + pos\n",
    "\n",
    "    for _ in range(2):\n",
    "        att = MultiHeadAttention(num_heads=heads, key_dim=d_model//heads)(x, x)\n",
    "        x = LayerNormalization()(x + att)\n",
    "        ff = Dense(ff_dim, activation=\"relu\")(x)\n",
    "        ff = Dense(d_model)(ff)\n",
    "        x = LayerNormalization()(x + ff)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", tf.keras.metrics.Precision(),\n",
    "                 tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# MODEL C — TCN (Dilated Causal Convolutions)\n",
    "# -------------------------------\n",
    "def TCN_block(x, filters, kernel=3, dilation=1):\n",
    "    # Causal convolution\n",
    "    conv1 = Conv1D(filters, kernel, dilation_rate=dilation,\n",
    "                   padding=\"causal\", activation=\"relu\")(x)\n",
    "    conv2 = Conv1D(filters, kernel, dilation_rate=dilation,\n",
    "                   padding=\"causal\", activation=\"relu\")(conv1)\n",
    "\n",
    "    # Residual connection\n",
    "    if x.shape[-1] != filters:\n",
    "        res = Conv1D(filters, 1, padding=\"same\")(x)\n",
    "    else:\n",
    "        res = x\n",
    "\n",
    "    return Add()([res, conv2])\n",
    "\n",
    "\n",
    "def build_tcn(seq_len, feat):\n",
    "    inp = Input(shape=(seq_len, feat))\n",
    "\n",
    "    x = TCN_block(inp, filters=64, dilation=1)\n",
    "    x = TCN_block(x,   filters=64, dilation=2)\n",
    "    x = TCN_block(x,   filters=64, dilation=4)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", tf.keras.metrics.Precision(),\n",
    "                 tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# EVALUATION\n",
    "# -------------------------------\n",
    "def evaluate_and_print(y_true, y_prob):\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1:\", f1_score(y_true, y_pred))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_true, y_prob))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "def train_model(model_builder, name, seq_len):\n",
    "    print(f\"\\n===== Running {name} =====\")\n",
    "    train_df, test_df, features, target = load_and_prepare_data()\n",
    "    train_bal, test_proc, scaler = preprocess_and_balance(train_df, test_df, features, target)\n",
    "\n",
    "    X_train, y_train = create_sequences(train_bal, features, target, seq_len)\n",
    "    X_test,  y_test  = create_sequences(test_proc, features, target, seq_len)\n",
    "\n",
    "    model = model_builder(seq_len, len(features))\n",
    "\n",
    "    cbs = [\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(patience=4, factor=0.5)\n",
    "    ]\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "              validation_split=0.2, callbacks=cbs, verbose=1)\n",
    "\n",
    "    y_prob = model.predict(X_test).ravel()\n",
    "    evaluate_and_print(y_test, y_prob)\n",
    "\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# MAIN — Run All 3 Models\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(build_cnn_lstm, \"CNN-LSTM\", SEQ_LENGTH)\n",
    "    train_model(build_transformer, \"Transformer\", SEQ_LENGTH)\n",
    "    train_model(build_tcn, \"TCN\", SEQ_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f50c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainfall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
